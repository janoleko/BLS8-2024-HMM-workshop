---
title: "Analysing ecological data with HMMs in R"
author: "Jan-Ole Koslik, Roland Langrock"
date: "3 March 2024"
# output: html_document
output:
    pdf_document:
        number_sections: true
        toc: false
header-includes:
  \renewcommand{\baselinestretch}{1.2}
fontsize: 12pt
bibliography: refs.bib
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  message = FALSE, error = FALSE, warning = FALSE,
  comment = NA
)
options(scipen = 999)
```

# Analysing tracking data with moveHMM

In this exercise, we analyse elephant tracking data using hidden Markov models (HMMs). The `R` package `moveHMM` allows us to model step lengths and turning angles using HMMs. We start by installing and loading `moveHMM`:

```{r load_moveHMM}
## Install and load required packages
# install.packages("moveHMM")
# install.packages("ggplot2")
# install.packages("dplyr")
library(moveHMM)
library(ggplot2)
library(dplyr)
```

The `R` package `moveHMM` has extensive documentation in several vignettes:
```{r moveHMM-documentation, eval = FALSE}
help(package = "moveHMM")
```

## Data pre-processing

Originally, 15 elephants from the Etosha National Park where fitted with GPS collars to collect hourly movement data (@tsalyuk2019temporal). For simplicity, the raw data have already been preprocessed and we consider the track of only one individual.

```{r data}
## Loading the data
elephant_data = read.csv("http://www.rolandlangrock.com/elephant_data.csv")

## Defining time of day variable (could also be done with lubridate)
elephant_data$timestamp = strptime(elephant_data$timestamp, 
                                   "%Y-%m-%d %H:%M:%S", tz = "GMT")

hours = as.numeric(format(elephant_data$timestamp, "%H"))
minutes = as.numeric(format(elephant_data$timestamp, "%M"))

elephant_data$timeOfDay = hours + (minutes/60)
```

The data are in the proper format and can be processed using `prepData` to compute step lengths and turning angles.

```{r prep_data, cache = TRUE}
## Compute step lengths and turning angles
hmm_data <- prepData(trackData = elephant_data, 
                     coordNames = c("location.long", "location.lat"), 
                     type = "LL")
```

Step lengths and turning angles are computed; the returned object is a data frame. The following commands can be used to get an overview of the data and to visualise the tracks:

```{r show_data, eval = FALSE}
## Get an overview of the data and to visualise the first 2 tracks
head(hmm_data)
plot(hmm_data, ask = FALSE)
```

## Model specification

Before we can fit an HMM to our data, we need to specify initial values for the parameters of the state-dependent distributions. As a starting point, it helps to have a look at the histograms of step lengths and turning angles:

```{r plot_histograms}
## Plot histograms of step length and turning angle
par(mfrow = c(1, 2))
hist(hmm_data$step, xlim = c(0, 4), breaks = 30, main = "", 
     xlab = "step length", border = "white")
hist(hmm_data$angle, main = "", 
     xlab = "turning angle", border = "white")
```

For an $N$-state HMM with gamma state-dependent distributions for the step lengths, we need $N$ mean, standard deviation, and, if applicable, zero probability parameters, respectively. Furthermore, with von Mises state-dependent distributions for the turning angles, we need $N$ mean and concentration parameters, respectively.

```{r initial_values}
## Initial values for the parameters of the state-dependent distributions
# For step length
step_mean_par0 <- c(0.1, 0.4, 1) # means
step_SD_par0 <- c(0.1, 0.3, 0.6) # SDs
step_zeroprob_par0 <- c(0.01, 0.01, 0.01) # zero probabilities
step_par0 <- c(step_mean_par0, step_SD_par0, step_zeroprob_par0)
# For turning angle
angle_mean_par0 <- c(0, 0, 0) # means
angle_concentration_par0 <- c(0.1, 0.9, 2) # concentrations
angle_par0 <- c(angle_mean_par0, angle_concentration_par0)
```

The above initial values provide a good choice, but feel free to try other values as well!

## Model fitting

To fit an HMM to data, we use `fitHMM`.

```{r model_fitting, message = FALSE, results='hide', cache = TRUE}
## Fit HMM
mod <- fitHMM(data = hmm_data, 
              nbStates = 3, 
              stepPar0 = step_par0,
              anglePar0 = angle_par0,
              stationary = TRUE, # we assume a stationary Markov chain
              verbose = 2)
```

## Results

To obtain the estimated model parameters, we can call the fitted model object:

```{r print_model, eval = TRUE}
## Print estimated model parameters
mod
```

To plot the fitted state-dependent distributions, we can use `plot`:

```{r plot_model, message = FALSE, results='hide', fig.width = 10, fig.height = 5, out.width="100%", fig.align="center"}
## Plot the fitted state-dependent distributions
par(mfrow = c(1, 2))
plot(mod, plotTracks = TRUE, ask = FALSE)
```

States 1 and 2 capture short and moderately long steps, which can be interpreted as resting and foraging behaviour, respectively. State 3 captures long, directed steps, which can be linked to travelling behaviour.

To obtain the decoded state sequence, we can use `viterbi`, `stateProbs`, and `plotStates`:

```{r state_decoding, eval = FALSE}
## Global state decoding
(states = viterbi(mod))
## Local state decoding
(stateprobs = stateProbs(mod))
## Show both
plotStates(mod, ask = FALSE, animals = 1)
```

## Adding covariates on the state transition probabilities

Covariates can be included in the hidden state model to capture the effect of environmental or individual-specific variables on the animalâ€™s behaviour. In `moveHMM`, covariates can be included by specifying a `formula`. Here, we are interested in modelling the diurnal variation present in the elphant's behaviour.

```{r timeofday, message = FALSE, results = 'hide', cache = TRUE}
## Fit HMM with trigonometric effect of time of day
mod_tod <- fitHMM(data = hmm_data, 
                  nbStates = 3, 
                  stepPar0 = step_par0,
                  anglePar0 = angle_par0,
                  formula = ~ sin(2*pi*timeOfDay/24) + cos(2*pi*timeOfDay/24), 
                  verbose = 2)
```

```{r mod_tod, message = FALSE, results = 'hide', cache = TRUE}
mod_tod
```

To visualise the probability of being in either of the 3 states as functions of the time of day, we can plot the stationary state probabilities using `plotStationary`.

```{r stationary_d2c, message = FALSE, results = 'hide', cache = TRUE, fig.width = 6, fig.height = 6, out.width = "50%", fig.align = "center"}
## Plot stationary state probabilities as function of d2c
plotStationary(mod_tod, plotCI = TRUE)
```

With the current implementation, these probabilities are only approximately correct. At the moment, we propose to look at the decoded states as a function of the time of day to interpret the diurnal variation in activity budgets: 

```{r statesbytod, message = FALSE, results = 'hide', cache = TRUE, fig.width = 6, fig.height = 6, out.width = "50%", fig.align = "center"}
# summarise relative frequencies by time of day
hmm_data$timeOfDay2 = round(hmm_data$timeOfDay)
hmm_data$states = viterbi(mod_tod)

# data frame of state frequencies by time of day
statefreq = hmm_data %>% 
  group_by(timeOfDay2) %>% 
  summarise(n = n(), freq1 = sum(states==1)/n, 
            freq2 = sum(states==2)/n, freq3 = sum(states==3)/n)

# make a bar plot
color = c("orange", "deepskyblue", "seagreen2")
barplot(cbind(freq1, freq2, freq3) ~ timeOfDay2, 
        data = statefreq, col = color, border = "white",
        xlab = "time of day", ylab = "relative state frequency")
legend("top", fill = color, legend = c("resting", "foraging", "travelling"), 
       box.lwd = 0, bg = "#ffffff98", border = "white")
```

We can increase model flexibility by including higher sine and cosine frequencies, which might be necessary when transition probabilities peak more than once in a day.

```{r timeofday2, message = FALSE, results = 'hide', cache = TRUE}
# Fit HMM with trigonometric effect of time of day
mod_tod2 <- fitHMM(data = hmm_data, 
                  nbStates = 3, 
                  stepPar0 = step_par0,
                  anglePar0 = angle_par0,
                  formula = ~ sin(2*pi*timeOfDay/24)+cos(2*pi*timeOfDay/24)+
                    # aditionally double the frequency
                    sin(2*pi*timeOfDay/12)+cos(2*pi*timeOfDay/12),
                  verbose = 2)
```

## Model selection

To compare and select among candidate models using information criteria, we can use `AIC`. Here, we select among HMMs with different covariate effects (for model selection with regard to the number of states, see Section 2):

```{r model_selection}
## Compute AIC
AIC(mod, mod_tod, mod_tod2)
```

In this case, we find that the most complicated model shows the best fit in terms of AIC. However, one should not only rely on the AIC for HMM model selection.

## Model checking

Pseudo-residuals are the most common way to check whether an HMM fits the data well. Similarly to linear model residuals, pseudo-residuals should be independent and standard normally distributed if the model assumptions are satisfied.

```{r model_checking, message = FALSE, results = 'hide', cache = TRUE, fig.width = 10, fig.height = 7.5, out.width = "100%", fig.align = "center"}
## Plot QQ and ACF plots
plotPR(mod_tod2)
```

The QQ plot is useful to identify deviations from normality, which suggest that the estimated state-dependent distributions do not capture the empirical distribution of the data perfectly. However, there is no indication for any major lack of fit -- in fact, a fit as good as the one shown here is quite rare in real-data applications. The ACF plot suggests that there is only little correlation that is not captured by our HMM. We have some difficulties in capturing the periodical structure caused by autocorrelation for lags ~ 24 hours.


# Analysing accelerometer data with momentuHMM

The `R` package `momentuHMM` extends `moveHMM` to allow for more general HMM formulations. Some of the main extensions are:

- possibility to include any number of observed variables, rather than just step length and turning angle, with many possible probability distributions (including normal, Poisson, beta, gamma, etc.);

- possibility to include covariate effects on the observation parameters, rather than only on the transition probabilities;

We start by detaching `moveHMM` if necessary (because some functions have the same names, which could cause conflicts), then loading `momentuHMM`, as well as `ggplot2` and a colour palette to create plots later on.

```{r load-packages}
# # Detach moveHMM if loaded
detach("package:moveHMM", unload = TRUE)
library(momentuHMM)
theme_set(theme_bw())
pal <- c("#E69F00", "#56B4E9", "#009E73")
```

The `R` package `momentuHMM` also has extensive documentation:
```{r momentuHMM-documentation, eval = FALSE}
help(package = "momentuHMM")
```

## Data

We consider accelerometer data collected for a whitetip shark over 4 days, provided by Yannis Papastamatiou (Florida International University, USA) and Yuuki Watanabe (National Institute of Polar Research, Japan). The raw data were at a very high sub-second resolution, such that we thinned them to a 1-min resolution for this analysis, for computational speed. The observed variable is the overall dynamic body acceleration (ODBA), which is a measure of the magnitude of the three-dimensional acceleration of the animal.

```{r load-data}
# Load whitetip shark accelerometer data
data <- read.csv("http://www.rolandlangrock.com/whitetip_data.csv")
data$Time <- as.POSIXct(data$Time)
head(data)
nrow(data)
```

The ODBA variable is strictly positive, and it is difficult to identify different states when plotting it, because most values are very small in contrast with a few large observations. To better distinguish between the different types of movement with small ODBA, we use the logarithm of the ODBA in the HMM analysis instead.

```{r log-odba, fig.width = 4, fig.height = 3, out.width="50%", fig.align="center", fig.show='hold'}
# Get logarithm of ODBA for HMM analysis
data$logODBA <- log(data$ODBA)

# Time series plots of ODBA and log-ODBA

ggplot(data, aes(Time, ODBA)) + geom_line()
ggplot(data, aes(Time, logODBA)) + geom_line()
```

Like in the tracking data example, we need to use the function `prepData` to prepare the format of the data set, and create a data object that will be recognised by `momentuHMM`. In this case, there is no need to derive step lengths and turning angles, so the function just copies the data frame passed as input. A difference to `moveHMM` is that we specify `coordNames = NULL` to indicate that there are no coordinates in the data (because we are not analysing location data), and the argument `covNames` to let `momentuHMM` know which variables are covariates (rather than response variables).

```{r prep-data}
data_hmm <- prepData(data = data, coordNames = NULL, covNames = "TimeOfDay")
```

## Model 1: two states

We don't know a priori how many states would best capture the patterns in the accelerometer data. This is a challenging problem in general, and this choice typically requires combining biological expertise and model checking to find a trade-off between model complexity and interpretation (@pohle2017selecting). It is often helpful to start from a simple model with only two states, then building up complexity if necessary.

### Model formulation

Before fitting a model, we need to specify a distribution for each observed variable. In the example, the log-ODBA variable is continuous and unbounded, so we propose modelling it using normal distributions. We also need to specify initial parameter values from which to start the likelihood optimisation. The idea is to pick values that are plausible given the data and our expectations of the states.

```{r 2state-init}
# List of observation distributions
dist <- list(logODBA = "norm")

# List of initial parameters
mean0 <- c(-4, -2)
sd0 <- c(0.5, 0.5)
Par0_2s <- list(logODBA = c(mean0, sd0))
```

### Model fitting

We can now pass these arguments, as well as the dataset and the number of states, to `fitHMM` for model fitting. While some of the argument names are slightly different to `moveHMM`, the syntax is still very similar.

```{r 2state-fit}
hmm_2s <- fitHMM(data = data_hmm, nbStates = 2, dist = dist, Par0 = Par0_2s)
```

### Model visualisation

We can visualise the state-dependent distributions of log-ODBA, on top of a histogram of observed values, using the `plot` function.

```{r 2state-plot, fig.width = 6, fig.height = 4, out.width="80%", fig.align="center"}
plot(hmm_2s, ask = FALSE)
```

We can use the function `viterbi` to obtain the most likely state sequence, and use it to colour a time series plot of the observations. To help with visualising patterns in each state, we only show the last 1000 observations, covering a little less than a day. 

```{r 2state-viterbi, fig.width = 5, fig.height = 3, out.width="70%", fig.align="center"}
data_hmm$viterbi_2s <- factor(viterbi(hmm_2s))

ggplot(tail(data_hmm, 1000), 
       aes(Time, logODBA, col = viterbi_2s, group = NA)) +
  geom_line() +
  scale_color_manual(values = pal, name = "State")
```

These plots suggest that state 2 captures both the lower tail and higher tail of the distribution of log-ODBA, whereas state 1 captures intermediate values. This makes biological interpretation a little tricky, because it looks like state 2 includes several behaviours (either no activity or high activity).

### Model checking

We again utilise Pseudo-residuals for checking the goodness of fit of our HMM.

```{r 2state-pseudores, fig.width = 7.5, fig.height = 2.5, out.width="100%", fig.align="center", fig.show='hold'}
# Plots of pseudo-residuals
plotPR(hmm_2s)
```

The QQ plot strongly deviates from the 1:1 diagonal in both tails, showing lack of fit. Potential improvements might include trying different distributions, or a model with more states. In the next section, we explore this latter option.

## Model 2: three states

The code required to create a 3-state model is very similar. The only thing we need to change is the `nbStates` argument in `fitHMM`, and the initial parameter values. We now need three values for each parameter (mean, standard deviation).

```{r 3state-fit, fig.width = 4, fig.height = 3, out.width="50%", fig.align="center", fig.show='hold'}
# List of initial parameters
mean0 <- c(-4, -3, -2)
sd0 <- c(0.5, 0.5, 0.5)
Par0_3s <- list(logODBA = c(mean0, sd0))

# Fit HMM
hmm_3s <- fitHMM(data = data_hmm, nbStates = 3, dist = dist, Par0 = Par0_3s)

# Plot state-dependent distributions
plot(hmm_3s, ask = FALSE, breaks = 50)

# Get most likely state sequence
data_hmm$viterbi_3s <- factor(viterbi(hmm_3s))

# Plot log-ODBA coloured by states
ggplot(tail(data_hmm, 1000), 
       aes(Time, logODBA, col = viterbi_3s, group = NA)) +
  geom_line() +
  scale_color_manual(values = pal, name = "State")
```

The three states are easier to interpret: state 1 seems to indicate normal swimming, state 2 may be some sort of gliding (?) and state 3 is linked to activity bursts. We can also look at the pseudo-residuals, which suggest that the fit is much better than that of the 2-state model.

```{r 3state-pseudores, fig.width = 7.5, fig.height = 2.5, out.width="100%", fig.align="center"}
plotPR(hmm_3s)
```

While still not perfect, these residuals look much better than the 2-state model's residuals. To obtain a better fit, it would probably make sense to include autoregressive structures in the state-dependent process (Slide 58), as the temporal resolution of the data is high.

## Simulating from the estimated model

Another option for checking the model fit is to simulate data from the estimated model and compare the simulated to the observed data. If the model describes the true data well, then the general patterns of these two should not deviate substantially.

```{r 3state_sim, fig.width = 7, fig.height = 5, out.width="90%", fig.align="center"}
simdata = simData(model = hmm_3s, 
                  states = TRUE, 
                  obsPerAnimal = nrow(data_hmm))
simdata$Time = data_hmm$Time

# Plotting original data coloured by decoded states
ggplot(tail(data_hmm, 500), 
       aes(Time, logODBA, col = viterbi_3s, group = NA)) +
  geom_line() +
  scale_color_manual(values = pal, name = "State") +
  labs(title = "real data")

# Plotting simulated data coloured by states
ggplot(tail(simdata, 500), 
       aes(Time, logODBA, col = factor(states), group = NA)) +
  geom_line() +
  scale_color_manual(values = pal, name = "State") +
  labs(title = "simulated data")
```

Overall, our model is able to fairly well replicate the main patterns also seen in the real data. We only see minor issues with state 3, which seems to exhibit shorter stays in the observed time series than implied by our model.

We can also visualise the marginal distribution implied by our model, i.e. the overall distribution of logODBA values:

```{r 3state_sim-hist, fig.width = 7, fig.height = 5, out.width="90%", fig.align="center"}

par(mfrow = c(1,2))
# histogram of original data
hist(data_hmm$logODBA, prob = TRUE, breaks = 50, border = "white",
     xlim = c(-5,-1), ylim = c(0,1.5), main = "real data", xlab = "logOBDA")

# histogram of simulated data
hist(simdata$logODBA, prob = TRUE, breaks = 50, border = "white", 
     xlim = c(-5,-1), ylim = c(0,1.5), main="simulated data", xlab="logOBDA")
```
The marginal distribution looks really good!

Lastly, we can investigate the autocorrelation function of the real and the simulated data.

```{r 3state_sim-acf, fig.width = 7, fig.height = 5, out.width="90%", fig.align="center"}
# autocorrelation function
par(mfrow = c(1,2))
acf(data_hmm$logODBA, main = "real data", bty = "n")
acf(na.omit(simdata$logODBA), main = "simulated data", bty = "n")
```

In this case, we find a minor lack of fit regarding larger lags which is really typical for HMM analyses due to the conditional independece assumption. This can be improved by including autoregressive structures in the state-dependent process (Slide 60), but as the inferential focus typically lies on the state process, it might not be worth the extra effort.

# References


